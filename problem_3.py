# -*- coding: utf-8 -*-
"""Problem_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HCK4t0JkdavXhOjsbWCnkRq3aDF6eNJg

**Mount Your Google Drive storage**

Enter the code using the link generating once you run the below cell
"""
#ECE 113 PROJECT PROBLEM 3
#TAIT KAMINSKI, DENNY TSAI, NATHAN CHEN, CHARLES BAI

from google.colab import drive
drive.mount('/content/drive')

"""**Assuming that you have**

1.   Mounted your Google Drive storage
2.   Uploaded the data files on Google Drive
3.   Have the path to your uploaded folder

Say you have placed all your data in "ECE113" folder on Google Drive or which is the case, update the `enter_your_folder_name` in the path

Eg. 

```
%cd "drive/My Drive/ECE113" 
```
"""

!ls

# Commented out IPython magic to ensure Python compatibility.
# update this as per your folder name
# %cd "/content/drive/My Drive/113final/Problem_3_data"

"""Make sure you are in the correct working directory"""

!pwd

"""Run the following code to verify whether you are in the correct directory on Google Colab"""

!ls

"""# Problem 3
## Chord  classification  task  using  deep  learning
"""

# importing relevant libraries
from scipy.io import wavfile
import numpy as np
import pandas as pd
import os
import math
from glob import glob

"""## Dataset Creation

In this part, we will just be using 2 class of chords as we are solving the binary classification task

Function used to pad any short audio file with zeros so that we have uniform size for each file

awgn a function used to add white gaussian noise to a signal given the specified snr in dB
"""

def pad_audio(data, fs, T):
    # Calculate target number of samples
    N_tar = int(fs * T)
    # Calculate number of zero samples to append
    shape = data.shape
    # Create the target shape    
    N_pad = N_tar - shape[0]
    #print("Padding with %s seconds of silence" % str(N_pad/fs) )
    shape = (N_pad,) + shape[1:]
    # Stack only if there is something to append    
    if shape[0] > 0:                
        if len(shape) > 1:
            return np.vstack((np.zeros(shape),
                              data))
        else:
            return np.hstack((np.zeros(shape),
                              data))
    else:
        return data



def awgn(signal, snr):
    N = len(signal)
    noise = np.random.normal(0,1,N)
    signal_power = np.sum(np.abs(signal)*np.abs(signal))/N
    noise_power = np.sum(np.abs(noise)*np.abs(noise))/N
    scale_factor = math.sqrt(signal_power/10**(10*math.log(signal_power/noise_power)/10))/noise_power #fill this in with the correct expression
    noise = noise * scale_factor
    return noise + signal

PATH = './Problem_3_data/training_data_3'

!ls './Problem_3_data/training_data_3'

audio_files_path = [y for x in os.walk(PATH) for y in glob(os.path.join(x[0], '*.wav'))]


# max_length of audiofile
T = 3.5

index = [i for i in range(len(audio_files_path))]
columns = ['data', 'label']
df_train2 = pd.DataFrame(index=index, columns=columns)
for i, file_path in enumerate(audio_files_path):
    fs, data = wavfile.read(file_path)
    out_data = pad_audio(data, fs, T)
    label = os.path.dirname(file_path).split("/")[-1]
    df_train2.loc[i] = [out_data, label]

assert(len(audio_files_path)==398)

y = df_train2.iloc[:, 1].values
X = df_train2.iloc[:, :-1].values
X = np.squeeze(X)
X = np.stack(X, axis=0)

from sklearn import preprocessing

labelencoder_y = preprocessing.LabelEncoder()
y = labelencoder_y.fit_transform(y)

"""## Splitting data into train and validation sets

The validation set is a small subset of the full dataset used to verify how well the model is performing or generalizing on unseen data
"""

from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=True, test_size=0.1)

"""### Importing necessary libraries used to build our deep neural network"""

# model building

import numpy as np
from keras.models import Sequential
from keras.layers import Dense,Activation, Flatten
from keras.optimizers import Adam
from sklearn import metrics

# set input dimensions to length of input data you will be feeding into the neural network
input_dim = 154350

model = Sequential()
model.add(Dense(512, input_dim=input_dim, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
# binary classification, hence just one output unit with sigmoid activation
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

"""---


Expect the model training to take ~3-4 mins for 5 epochs


---



---
"""

model.fit(X_train, y_train, epochs=5, batch_size=10)

_, accuracy = model.evaluate(X_val, y_val, verbose=0)

print("Accuracy on the validation dataset is :", accuracy)

"""As we can see above, within 5 epochs our model is able to perform binary classification with 72.5% accuracy.

## Your  task  is  to  use  the  extracted  features  from  Problem  1  and  find  out  the  binarychord classification for the set of 2 chords provided.

>  **(a)  Determine  the  class  of  test  audio  files  in  Problem_3/test_data_3
 using  the  fully  connected  network for binary classification**
"""

PATH= './Problem_3_data/test_data_3'
# max_length of audiofile
T = 3.5
index = [i for i in range(10)]
columns = ['data']
df_test_3 = pd.DataFrame(index=index, columns=columns)
for i, file_path in enumerate(glob(os.path.join(PATH, '*.wav'))):
    fs, data = wavfile.read(file_path)
    out_data = pad_audio(data, fs, T)
    df_test_3.loc[i] = [out_data]

X_test = df_test_3.iloc[:, :].values
X_test = np.squeeze(X_test)
X_test = np.stack(X_test, axis=0)
print(X_train.shape)

"""Now utilize the DFT feature extraction function you created in Problem 1 to extract DFT features for the 10 test examples in X_test. Then use these extracted featuers to perform binary classfication."""

########## Your code  ############

#dft
from scipy.fft import fft
import matplotlib.pyplot as plt

dft_features = []
for x in range(0,10) :
  r2 = fft(X_test[x])
  dft_features.append(abs(r2))
dftfeats = np.array(dft_features)
y_test = model.predict(X_test)
print("Predictions for X_test without DFT features: ", y_test)

X_train, X_val, y_train, y_val = train_test_split(dftfeats, y_test, shuffle=True, test_size=0.3)


#train a new nn
input_dim = 154350

model2 = Sequential()
model2.add(Dense(512, input_dim=input_dim, activation='relu'))
model2.add(Dense(256, activation='relu'))
model2.add(Dense(128, activation='relu'))
# binary classification, hence just one output unit with sigmoid activation
model2.add(Dense(1, activation='sigmoid'))
model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model2.fit(X_train, y_train, epochs=5, batch_size=10)
y_testdft = model2.predict(X_val)
print("Predictions for X_test with DFT features: ", y_testdft)

# evaluate new model
#_, accuracy = model2.evaluate(X_val, y_val, verbose=0)

#print("Accuracy on the validation dataset using the new model is :", accuracy)

"""> **(b).  Add  white  Gaussian  noise  to  all  of  the  test  data  at  signal to  noise  ratio  of  5,  0,  -5,  etc  and evaluate  the  performance.Implement  an  algorithm  to  improve  this  performance.   You  may choose  to perform  enhancement  on  the  noisy  signal  or  come  up  with  a  noise robust  feature extraction process.**"""

######## your code here #########

#Add white Gaussian noise to all of the test data at signal to noise ratio of 5, 0, -5, etc and evaluate the performance.
model3 = Sequential()
model3.add(Dense(512, input_dim=input_dim, activation='relu'))
model3.add(Dense(256, activation='relu'))
model3.add(Dense(128, activation='relu'))
# binary classification, hence just one output unit with sigmoid activation
model3.add(Dense(1, activation='sigmoid'))

model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

for nr in range(-10,16):
  if (nr % 5 == 0):
    print("Noise ratio: ", nr)
    y_test = model.predict(X_test)
    awgn_xtest = np.zeros((10,154350))
    for i in range(0, 10):
        awgn_xtest[i] = awgn(X_test[i], nr)
    X_train, X_val, y_train, y_val = train_test_split(awgn_xtest, y_test, shuffle=True, test_size=0.3)
    #train a new nn
    model3.fit(X_train, y_train, epochs=5, batch_size=10)
    # evaluate new model
    _, accuracy = model2.evaluate(X_val, y_val, verbose=0)
    print("Accuracy on the validation dataset using the new model with noise ratio = ", nr , " is : ", accuracy)

#Implement an algorithm to improve this performance. You may choose to perform enhancement on the noisy signal or come up with a noise robust feature extraction process.

"""> **(c).  Here,  we  add  zeros  to  the  end  of  each  audio  file  so  that  they  are  all  the  size.   Suggest  and implement a better method of length normalization.  Repeat part 3(a) for the new method.**"""

######## your code here #########
#A better method of length normalization could be just to take a set number of datapoints from each audio file equivalent to the number of datapoints in the smallest audio file.
audio_files_path = [y for x in os.walk(PATH) for y in glob(os.path.join(x[0], '*.wav'))]


# max_length of audiofile
T = 3.5

index = [i for i in range(len(audio_files_path))]
columns = ['data', 'label']
df_train2 = pd.DataFrame(index=index, columns=columns)
minshape = 999999999999999999999999999999999999999999999999
for i, file_path in enumerate(audio_files_path):
    fs, data = wavfile.read(file_path)
    if data.size < minshape:
      minshape = data.size

for i, file_path in enumerate(audio_files_path):
  fs, data = wavfile.read(file_path)
  label = os.path.dirname(file_path).split("/")[-1]
  df_train2.loc[i] = [data[0:minshape], label]

y = df_train2.iloc[:, 1].values
X = df_train2.iloc[:, :-1].values
X = np.squeeze(X)
X = np.stack(X, axis=0)

labelencoder_y = preprocessing.LabelEncoder()
y = labelencoder_y.fit_transform(y)

X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=True, test_size=0.1)
input_dim = minshape
 
model = Sequential()
model.add(Dense(512, input_dim=input_dim, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
# binary classification, hence just one output unit with sigmoid activation
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=5, batch_size=10)
_, accuracy = model.evaluate(X_val, y_val, verbose=0)
print("Accuracy on the validation dataset is :", accuracy)

#dft
PATH= './Problem_3_data/test_data_3'
# max_length of audiofile
T = 3.5
index = [i for i in range(10)]
columns = ['data']
df_test_3 = pd.DataFrame(index=index, columns=columns)
for i, file_path in enumerate(glob(os.path.join(PATH, '*.wav'))):
    fs, data = wavfile.read(file_path)
    df_test_3.loc[i] = [data[0:minshape]]

X_test = df_test_3.iloc[:, :].values
X_test = np.squeeze(X_test)
X_test = np.stack(X_test, axis=0)
print(X_train.shape)

from scipy.fft import fft
import matplotlib.pyplot as plt
 
dft_features = []
for x in range(0,10) :
  r2 = fft(X_test[x])
  dft_features.append(abs(r2))
dftfeats = np.array(dft_features)
y_test = model.predict(X_test)
print("Predictions for X_test without DFT features: ", y_test)
 
X_train, X_val, y_train, y_val = train_test_split(dftfeats, y_test, shuffle=True, test_size=0.3)
 
 
#train a new nn
input_dim = 60416
 
model2 = Sequential()
model2.add(Dense(512, input_dim=input_dim, activation='relu'))
model2.add(Dense(256, activation='relu'))
model2.add(Dense(128, activation='relu'))
# binary classification, hence just one output unit with sigmoid activation
model2.add(Dense(1, activation='sigmoid'))
model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
 
model2.fit(X_train, y_train, epochs=5, batch_size=10)
y_testdft = model2.predict(X_val)
print("Predictions for X_test with DFT features: ", y_testdft)

"""> **(d).  Highlight any specific advantages you see in the deep learning based approach when compared with the traditional methods.**"""

# Using deep learning allows us to have a much more nuanced model of preditions on data when compared to simpler machine learning methods because there are so many parameters involved in the training process with different weights; therefore one single categorization will not cause the entire model to tip in its direction and we can develop a far more intelligent model that can determine finer differences between categories of data.

"""## From this section, you must turn in:

1.   All code
2.   Prediction of classfication on test dataset, with and without DFT features
3.   Prediction of classfication on test dataset, with white Gaussian noise
"""

